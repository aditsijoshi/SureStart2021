{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Day19.1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditsijoshi/SureStart2021/blob/main/Day19_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uV69i9kEQ3V"
      },
      "source": [
        "Generative Adversarial Networks, or GANs, are an architecture for training generative models, such as deep convolutional neural networks for generating images.\n",
        "\n",
        "The GAN architecture is comprised of both a generator and a discriminator model. The generator is responsible for creating new outputs, such as images, that plausibly could have come from the original dataset. The generator model is typically implemented using a deep convolutional neural network and results-specialized layers that learn to fill in features in an image rather than extract features from an input image.\n",
        "\n",
        "Two common types of layers that can be used in the generator model are a upsample layer (UpSampling2D) that simply doubles the dimensions of the input and the transpose convolutional layer (Conv2DTranspose) that performs an inverse convolution operation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a6foQF_EQ3a",
        "outputId": "bab1596f-a5c0-4935-ac3e-4f795269d3b3"
      },
      "source": [
        "# example of using the upsampling layer\n",
        "from numpy import asarray\n",
        "from keras.models import Sequential\n",
        "from keras.layers import UpSampling2D\n",
        "# define input data\n",
        "X = asarray([[1, 2],\n",
        " [3, 4]])\n",
        "# show input data for context\n",
        "print(X)\n",
        "# reshape input data into one sample a sample with a channel\n",
        "X = X.reshape((1, 2, 2, 1))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(UpSampling2D(input_shape=(2, 2, 1)))\n",
        "# summarize the model\n",
        "model.summary()\n",
        "# make a prediction with the model\n",
        "yhat = model.predict(X)\n",
        "# reshape output to remove channel to make printing easier\n",
        "yhat = yhat.reshape((4, 4))\n",
        "# summarize output\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "up_sampling2d (UpSampling2D) (None, 4, 4, 1)           0         \n",
            "=================================================================\n",
            "Total params: 0\n",
            "Trainable params: 0\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[[1. 1. 2. 2.]\n",
            " [1. 1. 2. 2.]\n",
            " [3. 3. 4. 4.]\n",
            " [3. 3. 4. 4.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeqIAYGoEQ3d"
      },
      "source": [
        "Finally, the upsampled feature maps can be interpreted and filled in with hopefully useful detail by a Conv2D layer.\n",
        "\n",
        "The Conv2D has a single feature map as output to create the single image we require."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SNfXgM5EQ3f",
        "outputId": "844bc3c0-baa0-4074-ce40-c51bc72f19f1"
      },
      "source": [
        "# example of using upsampling in a simple generator model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import UpSampling2D\n",
        "from keras.layers import Conv2D\n",
        "# define model\n",
        "model = Sequential()\n",
        "# define input shape, output enough activations for for 128 5x5 image\n",
        "model.add(Dense(128 * 5 * 5, input_dim=100))\n",
        "# reshape vector of activations into 128 feature maps with 5x5\n",
        "model.add(Reshape((5, 5, 128)))\n",
        "# double input from 128 5x5 to 1 10x10 feature map\n",
        "model.add(UpSampling2D())\n",
        "# fill in detail in the upsampled feature maps and output a single image\n",
        "model.add(Conv2D(1, (3,3), padding='same'))\n",
        "# summarize model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 3200)              323200    \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 10, 10, 1)         1153      \n",
            "=================================================================\n",
            "Total params: 324,353\n",
            "Trainable params: 324,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X49ZP03UEQ3h"
      },
      "source": [
        "The Conv2DTranspose or transpose convolutional layer is more complex than a simple upsampling layer.\n",
        "\n",
        "A simple way to think about it is that it both performs the upsample operation and interprets the coarse input data to fill in the detail while it is upsampling. It is like a layer that combines the UpSampling2D and Conv2D layers into one layer. This is a crude understanding, but a practical starting point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-VnLettEQ3i",
        "outputId": "e1c43fa5-08bb-4040-9f9f-4d7d3fc96da5"
      },
      "source": [
        "from numpy import asarray\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2DTranspose\n",
        "# define input data\n",
        "X = asarray([[1, 2],\n",
        " [3, 4]])\n",
        "# show input data for context\n",
        "print(X)\n",
        "# reshape input data into one sample a sample with a channel\n",
        "X = X.reshape((1, 2, 2, 1))\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Conv2DTranspose(1, (1,1), strides=(2,2), input_shape=(2, 2, 1)))\n",
        "# summarize the model\n",
        "model.summary()\n",
        "# define weights that they do nothing\n",
        "weights = [asarray([[[[1]]]]), asarray([0])]\n",
        "# store the weights in the model\n",
        "model.set_weights(weights)\n",
        "# make a prediction with the model\n",
        "yhat = model.predict(X)\n",
        "# reshape output to remove channel to make printing easier\n",
        "yhat = yhat.reshape((4, 4))\n",
        "# summarize output\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_transpose (Conv2DTran (None, 4, 4, 1)           2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[[1. 0. 2. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [3. 0. 4. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPSd2dUCEQ3k"
      },
      "source": [
        "First, a Dense fully connected layer can be used to interpret the input vector and create a sufficient number of activations (outputs) that can be reshaped into a low-resolution version of our output image, in this case, 128 versions of a 5Ã—5 image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCf78VTWEQ3m",
        "outputId": "d4aec321-ca71-4bef-9ffd-7b279089ecf5"
      },
      "source": [
        "# example of using transpose conv in a simple generator model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Conv2D\n",
        "# define model\n",
        "model = Sequential()\n",
        "# define input shape, output enough activations for for 128 5x5 image\n",
        "model.add(Dense(128 * 5 * 5, input_dim=100))\n",
        "# reshape vector of activations into 128 feature maps with 5x5\n",
        "model.add(Reshape((5, 5, 128)))\n",
        "# double input from 128 5x5 to 1 10x10 feature map\n",
        "model.add(Conv2DTranspose(1, (3,3), strides=(2,2), padding='same'))\n",
        "# summarize model\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 3200)              323200    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 10, 10, 1)         1153      \n",
            "=================================================================\n",
            "Total params: 324,353\n",
            "Trainable params: 324,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnS1Clb7EQ3p",
        "outputId": "d97f11aa-015a-4645-8b74-b39a1f067a75"
      },
      "source": [
        "# example of using the transpose convolutional layer\r\n",
        "from numpy import asarray\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Conv2DTranspose\r\n",
        "# define input data\r\n",
        "X = asarray([[1, 2],\r\n",
        " [3, 4]])\r\n",
        "# show input data for context\r\n",
        "print(X)\r\n",
        "# reshape input data into one sample a sample with a channel\r\n",
        "X = X.reshape((1, 2, 2, 1))\r\n",
        "# define model\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2DTranspose(1, (1,1), strides=(2,2), input_shape=(2, 2, 1)))\r\n",
        "# summarize the model\r\n",
        "model.summary()\r\n",
        "# define weights that they do nothing\r\n",
        "weights = [asarray([[[[1]]]]), asarray([0])]\r\n",
        "# store the weights in the model\r\n",
        "model.set_weights(weights)\r\n",
        "# make a prediction with the model\r\n",
        "yhat = model.predict(X)\r\n",
        "# reshape output to remove channel to make printing easier\r\n",
        "yhat = yhat.reshape((4, 4))\r\n",
        "# summarize output\r\n",
        "print(yhat)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2]\n",
            " [3 4]]\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_transpose (Conv2DTran (None, 4, 4, 1)           2         \n",
            "=================================================================\n",
            "Total params: 2\n",
            "Trainable params: 2\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[[1. 0. 2. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [3. 0. 4. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTUR1_htEQ3q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}