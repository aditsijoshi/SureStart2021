{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Day19.2.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditsijoshi/SureStart2021/blob/main/Day19_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxzqVqV8FXQa"
      },
      "source": [
        "\"Autoencoding\" is a data compression algorithm where the compression and decompression functions are 1) data-specific, 2) lossy, and 3) learned automatically from examples rather than engineered by a human. Additionally, in almost all contexts where the term \"autoencoder\" is used, the compression and decompression functions are implemented with neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs4WTj2aFXQo"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "# This is the size of our encoded representations\n",
        "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
        "\n",
        "# This is our input image\n",
        "input_img = keras.Input(shape=(784,))\n",
        "# \"encoded\" is the encoded representation of the input\n",
        "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
        "# \"decoded\" is the lossy reconstruction of the input\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "# This model maps an input to its reconstruction\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyWtd4E8FXQq"
      },
      "source": [
        "# This model maps an input to its encoded representation\n",
        "encoder = keras.Model(input_img, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRl1EmVxFXQr"
      },
      "source": [
        "# This is our encoded (32-dimensional) input\n",
        "encoded_input = keras.Input(shape=(encoding_dim,))\n",
        "# Retrieve the last layer of the autoencoder model\n",
        "decoder_layer = autoencoder.layers[-1]\n",
        "# Create the decoder model\n",
        "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o1zL1vAFXQt"
      },
      "source": [
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlwXhBg_FXQu"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "(x_train, _), (x_test, _) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZtPWEwRFXQv",
        "outputId": "6c2d6388-470d-4055-94c9-7898e43195cf"
      },
      "source": [
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 784)\n",
            "(10000, 784)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0pUShCdFXQx",
        "outputId": "35ff892b-1371-4cbf-d929-9be2d63527bf"
      },
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.3839 - val_loss: 0.1891\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1794 - val_loss: 0.1540\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1502 - val_loss: 0.1348\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - ETA: 0s - loss: 0.132 - 1s 3ms/step - loss: 0.1328 - val_loss: 0.1225\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1216 - val_loss: 0.1135\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1132 - val_loss: 0.1071\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1073 - val_loss: 0.1025\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.1030 - val_loss: 0.0993\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1000 - val_loss: 0.0970\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0978 - val_loss: 0.0953\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0964 - val_loss: 0.0944\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0954 - val_loss: 0.0938\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0950 - val_loss: 0.0933\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0943 - val_loss: 0.0930\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0942 - val_loss: 0.0928\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0939 - val_loss: 0.0926\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0937 - val_loss: 0.0925\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0937 - val_loss: 0.0924\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0935 - val_loss: 0.0922\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0933 - val_loss: 0.0922\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0932 - val_loss: 0.0922\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0932 - val_loss: 0.0921\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0931 - val_loss: 0.0921\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0932 - val_loss: 0.0921\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0933 - val_loss: 0.0920\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0920\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0919\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0931 - val_loss: 0.0919\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0918\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0918\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0918\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0918\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0930 - val_loss: 0.0917\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0917\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0918\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0917\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0916\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0928 - val_loss: 0.0916\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0916\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0929 - val_loss: 0.0916\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0927 - val_loss: 0.0915\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0926 - val_loss: 0.0916\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 0.0924 - val_loss: 0.0917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x22b15345b88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75R09QQdFXQz"
      },
      "source": [
        "# Encode and decode some digits\n",
        "# Note that we take them from the *test* set\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsgE3GwBFXQ0",
        "outputId": "8a0ed5b7-88b1-452b-c600-2f59b891d72c"
      },
      "source": [
        "# Use Matplotlib (don't ask)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "n = 10  # How many digits we will display\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 20 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBHCRM7GFXQ2"
      },
      "source": [
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAm72h_vFXQ3"
      },
      "source": [
        "from keras import regularizers\n",
        "\n",
        "encoding_dim = 32\n",
        "\n",
        "input_img = keras.Input(shape=(784,))\n",
        "# Add a Dense layer with a L1 activity regularizer\n",
        "encoded = layers.Dense(encoding_dim, activation='relu',\n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_img)\n",
        "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_ZeJ92uFXQ4"
      },
      "source": [
        "input_img = keras.Input(shape=(784,))\n",
        "encoded = layers.Dense(128, activation='relu')(input_img)\n",
        "encoded = layers.Dense(64, activation='relu')(encoded)\n",
        "encoded = layers.Dense(32, activation='relu')(encoded)\n",
        "\n",
        "decoded = layers.Dense(64, activation='relu')(encoded)\n",
        "decoded = layers.Dense(128, activation='relu')(decoded)\n",
        "decoded = layers.Dense(784, activation='sigmoid')(decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OmvnMWQFXQ5",
        "outputId": "3e30618f-59dd-4136-fdb1-b9e9502aa78e"
      },
      "source": [
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.3353 - val_loss: 0.1647\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1562 - val_loss: 0.1340\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1318 - val_loss: 0.1224\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1227 - val_loss: 0.1160\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1160 - val_loss: 0.1114\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1117 - val_loss: 0.1070\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1077 - val_loss: 0.1046\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.1046 - val_loss: 0.1019\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1024 - val_loss: 0.0999\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.1007 - val_loss: 0.0985\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0990 - val_loss: 0.0975\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0979 - val_loss: 0.0961\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0966 - val_loss: 0.0952\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0954 - val_loss: 0.0939\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0945 - val_loss: 0.0931\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0934 - val_loss: 0.0926\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0929 - val_loss: 0.0915\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0921 - val_loss: 0.0908\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0915 - val_loss: 0.0905\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0908 - val_loss: 0.0898\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0905 - val_loss: 0.0895\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0899 - val_loss: 0.0889\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0894 - val_loss: 0.0890\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0893 - val_loss: 0.0882\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0890 - val_loss: 0.0881\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0884 - val_loss: 0.0879\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0883 - val_loss: 0.0876\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0878 - val_loss: 0.0872\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0877 - val_loss: 0.0871\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0873 - val_loss: 0.0872\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0873 - val_loss: 0.0866\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0870 - val_loss: 0.0862\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0869 - val_loss: 0.0864\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0865 - val_loss: 0.0860\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0862 - val_loss: 0.0859\n",
            "Epoch 36/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0859 - val_loss: 0.0857\n",
            "Epoch 37/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0860 - val_loss: 0.0856\n",
            "Epoch 38/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0859 - val_loss: 0.0853\n",
            "Epoch 39/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0856 - val_loss: 0.0849\n",
            "Epoch 40/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0855 - val_loss: 0.0850\n",
            "Epoch 41/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0853 - val_loss: 0.0849\n",
            "Epoch 42/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0852 - val_loss: 0.0847\n",
            "Epoch 43/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0851 - val_loss: 0.0847\n",
            "Epoch 44/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0850 - val_loss: 0.0847\n",
            "Epoch 45/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0847 - val_loss: 0.0843\n",
            "Epoch 46/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0845 - val_loss: 0.0845\n",
            "Epoch 47/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0846 - val_loss: 0.0841\n",
            "Epoch 48/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0844 - val_loss: 0.0839\n",
            "Epoch 49/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0842 - val_loss: 0.0840\n",
            "Epoch 50/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0843 - val_loss: 0.0841\n",
            "Epoch 51/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.0843 - val_loss: 0.0839\n",
            "Epoch 52/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0842 - val_loss: 0.0840\n",
            "Epoch 53/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0840 - val_loss: 0.0836\n",
            "Epoch 54/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0840 - val_loss: 0.0836\n",
            "Epoch 55/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0839 - val_loss: 0.0834\n",
            "Epoch 56/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0833\n",
            "Epoch 57/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0838 - val_loss: 0.0834\n",
            "Epoch 58/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0833\n",
            "Epoch 59/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0835 - val_loss: 0.0831\n",
            "Epoch 60/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0836 - val_loss: 0.0835\n",
            "Epoch 61/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0837 - val_loss: 0.0831\n",
            "Epoch 62/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0833 - val_loss: 0.0833\n",
            "Epoch 63/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0831 - val_loss: 0.0831\n",
            "Epoch 64/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0834 - val_loss: 0.0830\n",
            "Epoch 65/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0832 - val_loss: 0.0834\n",
            "Epoch 66/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0834 - val_loss: 0.0830\n",
            "Epoch 67/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0831 - val_loss: 0.0830\n",
            "Epoch 68/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0833 - val_loss: 0.0831\n",
            "Epoch 69/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0829 - val_loss: 0.0828\n",
            "Epoch 70/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0831 - val_loss: 0.0829\n",
            "Epoch 71/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0829 - val_loss: 0.0829\n",
            "Epoch 72/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0829 - val_loss: 0.0829\n",
            "Epoch 73/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0829 - val_loss: 0.0827\n",
            "Epoch 74/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0828 - val_loss: 0.0825\n",
            "Epoch 75/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0826 - val_loss: 0.0825\n",
            "Epoch 76/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0828 - val_loss: 0.0824\n",
            "Epoch 77/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0825 - val_loss: 0.0825\n",
            "Epoch 78/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0827 - val_loss: 0.0830\n",
            "Epoch 79/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0826 - val_loss: 0.0824\n",
            "Epoch 80/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0824 - val_loss: 0.0826\n",
            "Epoch 81/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0827 - val_loss: 0.0828\n",
            "Epoch 82/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0826 - val_loss: 0.0822\n",
            "Epoch 83/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0826 - val_loss: 0.0823\n",
            "Epoch 84/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0825 - val_loss: 0.0823\n",
            "Epoch 85/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0823 - val_loss: 0.0822\n",
            "Epoch 86/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0823 - val_loss: 0.0824\n",
            "Epoch 87/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0823 - val_loss: 0.0821\n",
            "Epoch 88/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - val_loss: 0.0822\n",
            "Epoch 89/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0822 - val_loss: 0.0820\n",
            "Epoch 90/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - val_loss: 0.0821\n",
            "Epoch 91/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - val_loss: 0.0821\n",
            "Epoch 92/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0821 - val_loss: 0.0820\n",
            "Epoch 93/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0821 - val_loss: 0.0822\n",
            "Epoch 94/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0821 - val_loss: 0.0820\n",
            "Epoch 95/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0821 - val_loss: 0.0821\n",
            "Epoch 96/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0823 - val_loss: 0.0819\n",
            "Epoch 97/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0818 - val_loss: 0.0818\n",
            "Epoch 98/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0819 - val_loss: 0.0818\n",
            "Epoch 99/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.0820 - val_loss: 0.0818\n",
            "Epoch 100/100\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 0.0818 - val_loss: 0.0818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x22b1ffe7888>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-ms3YSkFXQ8"
      },
      "source": [
        "Convolutional autoencoder\n",
        "Since our inputs are images, it makes sense to use convolutional neural networks (convnets) as encoders and decoders. In practical settings, autoencoders applied to images are always convolutional autoencoders --they simply perform much better.\n",
        "\n",
        "Let's implement one. The encoder will consist in a stack of Conv2D and MaxPooling2D layers (max pooling being used for spatial down-sampling), while the decoder will consist in a stack of Conv2D and UpSampling2D layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4XAgvhRFXQ9"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "input_img = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZSgDaQ3FXQ_"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OwXB7aPFXRA"
      },
      "source": [
        "tensorboard --logdir=/tmp/autoencoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er0k5eOQFXRB",
        "outputId": "ed29aa62-76d9-49f2-92e7-6502aabb6ae9"
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 33s 70ms/step - loss: 0.2877 - val_loss: 0.1474\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 32s 69ms/step - loss: 0.1429 - val_loss: 0.1283\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 32s 69ms/step - loss: 0.1263 - val_loss: 0.1190\n",
            "Epoch 4/50\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.1181 - val_loss: 0.1139\n",
            "Epoch 5/50\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.1136 - val_loss: 0.1098\n",
            "Epoch 6/50\n",
            "469/469 [==============================] - 32s 69ms/step - loss: 0.1103 - val_loss: 0.1073\n",
            "Epoch 7/50\n",
            "469/469 [==============================] - 33s 70ms/step - loss: 0.1079 - val_loss: 0.1051\n",
            "Epoch 8/50\n",
            "469/469 [==============================] - 32s 69ms/step - loss: 0.1057 - val_loss: 0.1036\n",
            "Epoch 9/50\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.1043 - val_loss: 0.1025\n",
            "Epoch 10/50\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.1031 - val_loss: 0.1012\n",
            "Epoch 11/50\n",
            "469/469 [==============================] - 33s 69ms/step - loss: 0.1021 - val_loss: 0.1002\n",
            "Epoch 12/50\n",
            "256/469 [===============>..............] - ETA: 14s - loss: 0.1014"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-20-3b6b3754a0be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0CkqKQxFXRC",
        "outputId": "0305c386-25e2-4016-b334-db98312452ad"
      },
      "source": [
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=50,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "469/469 [==============================] - 33s 71ms/step - loss: 0.1007 - val_loss: 0.0993\n",
            "Epoch 2/50\n",
            "469/469 [==============================] - 33s 69ms/step - loss: 0.1000 - val_loss: 0.0984\n",
            "Epoch 3/50\n",
            "469/469 [==============================] - 32s 68ms/step - loss: 0.0994 - val_loss: 0.0979\n",
            "Epoch 4/50\n",
            "107/469 [=====>........................] - ETA: 26s - loss: 0.0991"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-21-3b6b3754a0be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m                 callbacks=[TensorBoard(log_dir='/tmp/autoencoder')])\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59207vEPFXRE"
      },
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n + 1):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gw1v30cXFXRF"
      },
      "source": [
        "encoder = keras.Model(input_img, encoded)\n",
        "encoded_imgs = encoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 8))\n",
        "for i in range(1, n + 1):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(encoded_imgs[i].reshape((4, 4 * 8)).T)\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcW7GXgJFXRG"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "\n",
        "(x_train, _), (x_test, _) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "noise_factor = 0.5\n",
        "x_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \n",
        "x_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \n",
        "\n",
        "x_train_noisy = np.clip(x_train_noisy, 0., 1.)\n",
        "x_test_noisy = np.clip(x_test_noisy, 0., 1.)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNWXwX5lFXRH"
      },
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 2))\n",
        "for i in range(1, n + 1):\n",
        "    ax = plt.subplot(1, n, i)\n",
        "    plt.imshow(x_test_noisy[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR09B5koFXRJ"
      },
      "source": [
        "input_img = keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# At this point the representation is (7, 7, 32)\n",
        "\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fooy5hqCFXRK"
      },
      "source": [
        "autoencoder.fit(x_train_noisy, x_train,\n",
        "                epochs=100,\n",
        "                batch_size=128,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test_noisy, x_test),\n",
        "                callbacks=[TensorBoard(log_dir='/tmp/tb', histogram_freq=0, write_graph=False)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJLmu_7QFXRQ"
      },
      "source": [
        "timesteps = ...  # Length of your sequences\n",
        "input_dim = ... \n",
        "latent_dim = ...\n",
        "\n",
        "inputs = keras.Input(shape=(timesteps, input_dim))\n",
        "encoded = layers.LSTM(latent_dim)(inputs)\n",
        "\n",
        "decoded = layers.RepeatVector(timesteps)(encoded)\n",
        "decoded = layers.LSTM(input_dim, return_sequences=True)(decoded)\n",
        "\n",
        "sequence_autoencoder = keras.Model(inputs, decoded)\n",
        "encoder = keras.Model(inputs, encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFHKuLo6FXRS"
      },
      "source": [
        "original_dim = 28 * 28\n",
        "intermediate_dim = 64\n",
        "latent_dim = 2\n",
        "\n",
        "inputs = keras.Input(shape=(original_dim,))\n",
        "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
        "z_mean = layers.Dense(latent_dim)(h)\n",
        "z_log_sigma = layers.Dense(latent_dim)(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wudHM0-FXRT"
      },
      "source": [
        "from keras import backend as K\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
        "                              mean=0., stddev=0.1)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "z = layers.Lambda(sampling)([z_mean, z_log_sigma])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WJVfKqvFXRV"
      },
      "source": [
        "# Create encoder\n",
        "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
        "\n",
        "# Create decoder\n",
        "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
        "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
        "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "# instantiate VAE model\n",
        "outputs = decoder(encoder(inputs)[2])\n",
        "vae = keras.Model(inputs, outputs, name='vae_mlp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SJrkQNdFXRX"
      },
      "source": [
        "What we've done so far allows us to instantiate 3 models:\n",
        "\n",
        "an end-to-end autoencoder mapping inputs to reconstructions\n",
        "an encoder mapping inputs to the latent space\n",
        "a generator that can take points on the latent space and will output the corresponding reconstructed samples.\n",
        "We train the model using the end-to-end model, with a custom loss function: the sum of a reconstruction term, and the KL divergence regularization term."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKyiCwLmFXRZ"
      },
      "source": [
        "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
        "reconstruction_loss *= original_dim\n",
        "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "kl_loss *= -0.5\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "vae.add_loss(vae_loss)\n",
        "vae.compile(optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJqs4l8GFXRd"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "\n",
        "vae.fit(x_train, x_train,\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        validation_data=(x_test, x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHM6yUQ1FXRf"
      },
      "source": [
        "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
        "plt.colorbar()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9GOEc5vFXRg"
      },
      "source": [
        "# Display a 2D manifold of the digits\n",
        "n = 15  # figure with 15x15 digits\n",
        "digit_size = 28\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "# We will sample n points within [-15, 15] standard deviations\n",
        "grid_x = np.linspace(-15, 15, n)\n",
        "grid_y = np.linspace(-15, 15, n)\n",
        "\n",
        "for i, yi in enumerate(grid_x):\n",
        "    for j, xi in enumerate(grid_y):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
        "        figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(figure)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}