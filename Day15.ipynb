{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day15.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNwc2ukFFvND+YUkCgovyhF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aditsijoshi/SureStart2021/blob/main/Day15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiThYeRKPcdJ"
      },
      "source": [
        "import os # accessing directory structure\r\n",
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt # plotting\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from  IPython.display import display\r\n",
        "import plotly.express as px\r\n",
        "\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, experimental, MaxPool2D, BatchNormalization\r\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy, binary_crossentropy\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau \r\n",
        "from tensorflow.data import Dataset\r\n",
        "from tensorflow.keras import Input, Model\r\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.random import set_seed\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "from tensorflow import test\r\n",
        "import random\r\n",
        "\r\n",
        "# Set Seed\r\n",
        "np.random.seed(11)\r\n",
        "set_seed(11)\r\n",
        "random.seed(11)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogpdxDvXRGY9",
        "outputId": "a395ce7f-6910-4350-fc8b-ce1bac6f1cc7"
      },
      "source": [
        "\r\n",
        "        \r\n",
        "age_gender_data = pd.read_csv(\"/content/age_gender.csv\")\r\n",
        "age_gender_data.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1060 entries, 0 to 1059\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   age        1060 non-null   int64 \n",
            " 1   ethnicity  1060 non-null   int64 \n",
            " 2   gender     1060 non-null   int64 \n",
            " 3   img_name   1060 non-null   object\n",
            " 4   pixels     1060 non-null   object\n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 41.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "Kbevv6AWRpHm",
        "outputId": "f84326b0-ab57-4110-fd85-c67c97702788"
      },
      "source": [
        "age_gender_data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>ethnicity</th>\n",
              "      <th>gender</th>\n",
              "      <th>img_name</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219203650636.jpg.chip.jpg</td>\n",
              "      <td>129 128 128 126 127 130 133 135 139 142 145 14...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219222752047.jpg.chip.jpg</td>\n",
              "      <td>164 74 111 168 169 171 175 182 184 188 193 199...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161219222832191.jpg.chip.jpg</td>\n",
              "      <td>67 70 71 70 69 67 70 79 90 103 116 132 145 155...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161220144911423.jpg.chip.jpg</td>\n",
              "      <td>193 197 198 200 199 200 202 203 204 205 208 21...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>20161220144914327.jpg.chip.jpg</td>\n",
              "      <td>202 205 209 210 209 209 210 211 212 214 218 21...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  ...                                             pixels\n",
              "0    1  ...  129 128 128 126 127 130 133 135 139 142 145 14...\n",
              "1    1  ...  164 74 111 168 169 171 175 182 184 188 193 199...\n",
              "2    1  ...  67 70 71 70 69 67 70 79 90 103 116 132 145 155...\n",
              "3    1  ...  193 197 198 200 199 200 202 203 204 205 208 21...\n",
              "4    1  ...  202 205 209 210 209 209 210 211 212 214 218 21...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "7-KvtYm2R0D_",
        "outputId": "239de160-a26b-4748-fc77-5b5913154047"
      },
      "source": [
        "sns.countplot(x='age', data=age_gender_data) #age distribution"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f2a12838f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6nU6nbwSIGM"
      },
      "source": [
        "sns.countplot(x='gender', data=age_gender_data) #gender distribution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IckIwzkSSLpT"
      },
      "source": [
        "# Select only person who has age more than 18 \r\n",
        "age_gender_data = age_gender_data[age_gender_data['age'] >= 18]\r\n",
        "sns.countplot(x='age', data=age_gender_data) #age distribution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj7sQTzMSLfn"
      },
      "source": [
        "age_gender_data.reset_index(drop=True, inplace=True)\r\n",
        "age_gender_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRna-ZizSWaD"
      },
      "source": [
        "age_gender_data.isnull().sum() # Check null data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaBHiJ32SYiZ"
      },
      "source": [
        "# Input image configuration\r\n",
        "num_pixels = len(age_gender_data['pixels'][0].split(' '))\r\n",
        "dimension = int(np.sqrt(num_pixels))\r\n",
        "img_width = dimension\r\n",
        "img_height = dimension\r\n",
        "\r\n",
        "print(\"Pixels: {}\".format(num_pixels))\r\n",
        "print(\"Width: {0}, Height: {1}\".format(img_width, img_height))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muONLq-wSfI8"
      },
      "source": [
        "# Splitting dataset into X and y\r\n",
        "X_img = age_gender_data.iloc[:,4].copy()\r\n",
        "y_age = age_gender_data.iloc[:,0].copy()\r\n",
        "y_ethnicity = age_gender_data.iloc[:,1].copy()\r\n",
        "y_gender = age_gender_data.iloc[:,2].copy()\r\n",
        "\r\n",
        "# splitting the data into train and te sets.\r\n",
        "X_train, X_te, y_train, y_te = train_test_split(X_img,y_gender,test_size=0.3,random_state=11)\r\n",
        "# splitting 'te' set into validation and test set\r\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_te,y_te,test_size=0.15,random_state=11)\r\n",
        "\r\n",
        "def str_to_npArr(x):\r\n",
        "    '''\r\n",
        "    Function to convert pixel data (string) into numpy_array of pixels\r\n",
        "    '''\r\n",
        "    x = x.reset_index(drop=True)\r\n",
        "    x = x.apply(lambda x: np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\r\n",
        "    return np.array([x[i].reshape(img_width, img_height, 1) for i in range(x.shape[0])])\r\n",
        "\r\n",
        "# Converting the string of pixels into image array for each of train, val and test set and normalization\r\n",
        "X_train = str_to_npArr(X_train)\r\n",
        "X_test = str_to_npArr(X_test)\r\n",
        "X_val = str_to_npArr(X_val)\r\n",
        "\r\n",
        "print(\"Traget: shape = (16593, 48, 48, 1), type = <class 'numpy.ndarray'>\")\r\n",
        "print(\"Current: shape = {}, type = {}\".format(X_train.shape, type(X_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UDka3rKSjtq"
      },
      "source": [
        "target_columns = ['gender', 'ethnicity', 'age']\r\n",
        "\r\n",
        "age_gender_data_preprocess = age_gender_data.drop('img_name', axis=1)\r\n",
        "y = age_gender_data_preprocess[target_columns]\r\n",
        "X = age_gender_data_preprocess.drop(target_columns, axis=1)\r\n",
        "\r\n",
        "print(X)\r\n",
        "print(\"--------------------------------------------------------\")\r\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WmgrnHWSn5c"
      },
      "source": [
        "X = X['pixels'].apply(lambda x: np.array(x.split(), dtype=\"float32\")) #converting data to numpy array\r\n",
        "X = np.array(X)/255.0 # normalization\r\n",
        "X = np.array([ X[i].reshape(48,48,1) for i in range(X.shape[0]) ])\r\n",
        "\r\n",
        "print(\"Traget: X Shape: {}\".format(X.shape))\r\n",
        "print(\"Current: X Shape: {}\".format(X.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "290uXU5jSrEe"
      },
      "source": [
        "y_gender = np.array(y['gender'])\r\n",
        "y_ethnicity = np.array(y['ethnicity'])\r\n",
        "y_age = np.array(y['age'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfIQRVqvSwGk"
      },
      "source": [
        "rows = 20 # rows in subplots\r\n",
        "cols = 5 # columns in subplots\r\n",
        "samp = random.sample(range(X.shape[0]),rows*cols) #selecting 100 random samples\r\n",
        "x_samp = X[samp,:,:,:]\r\n",
        "y_samp_gender = y_gender[samp]\r\n",
        "y_samp_age = y_age[samp]\r\n",
        "    \r\n",
        "fig,ax = plt.subplots(rows,cols,figsize=(16,60))\r\n",
        "r = 0\r\n",
        "c = 0   \r\n",
        "\r\n",
        "for i in range(rows*cols):\r\n",
        "    aa = x_samp[i,:,:,:].reshape(48,48)\r\n",
        "    ax[r,c].axis(\"off\")\r\n",
        "    ax[r,c].imshow(aa,cmap=\"gray\")\r\n",
        "    ax[r,c].set_title(f\"Gender: {'Female' if y_samp_gender[i]==1 else 'Male'}, Age: {y_samp_age[i]}\")\r\n",
        "    c+=1\r\n",
        "    if c == cols:\r\n",
        "        c=0\r\n",
        "        r+=1\r\n",
        "        \r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J7HNgI3S0cR"
      },
      "source": [
        "train_data_gen = ImageDataGenerator(rotation_range=30,\r\n",
        "                                   width_shift_range=1,\r\n",
        "                                    brightness_range=[0.8,1.2],\r\n",
        "                                    zoom_range=[0.8,1.2],\r\n",
        "                                    rescale=1/255\r\n",
        "                                   )\r\n",
        "val_data_gen = ImageDataGenerator(rescale=1/255)\r\n",
        "\r\n",
        "test_data_gen = ImageDataGenerator(rescale=1/255)\r\n",
        "set_seed(11)\r\n",
        "random.seed(11)\r\n",
        "np.random.seed(11)\r\n",
        "\r\n",
        "val_data = val_data_gen.flow(X_val,y_val,\r\n",
        "                                   seed=11,shuffle=False)\r\n",
        "\r\n",
        "test_data = test_data_gen.flow(X_test,y_test,\r\n",
        "                                   seed=11,shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOyOYoW4S8Vf"
      },
      "source": [
        "fig,ax = plt.subplots(10,5,figsize=(15,25))\r\n",
        "for n in range(10):    \r\n",
        "    r = random.sample(range(X.shape[0]),1)[0]\r\n",
        "    ax[n,0].imshow(X[r].reshape(48,48),cmap=\"gray\")\r\n",
        "    ax[n,0].set_title(\"Original\")\r\n",
        "    ax[n,0].axis(\"off\")\r\n",
        "    for i in range(1,5):\r\n",
        "        ax[n,i].imshow(train_data_gen.random_transform(X[r]).reshape(48,48),cmap=\"gray\")\r\n",
        "        ax[n,i].set_title(\"Augmented\")\r\n",
        "        ax[n,i].axis(\"off\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "949CfBaZS_50"
      },
      "source": [
        "# Model configuration\r\n",
        "batch_size = 32\r\n",
        "img_width, img_height, img_num_channels = 48, 48, 1\r\n",
        "loss_function = sparse_categorical_crossentropy\r\n",
        "no_classes = 2\r\n",
        "no_epochs = 50\r\n",
        "optimizer = Adam()\r\n",
        "verbosity = 1\r\n",
        "num_folds = 10\r\n",
        "activation='softmax'\r\n",
        "\r\n",
        "# Determine shape of the data\r\n",
        "input_shape = (img_width, img_height, img_num_channels)\r\n",
        "input_shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vu6hjwVTH6r"
      },
      "source": [
        "# Set Seed\r\n",
        "random.seed(11)\r\n",
        "set_seed(11)\r\n",
        "np.random.seed(11)\r\n",
        "\r\n",
        "# Define the K-fold Cross Validator\r\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdanycAmTakF"
      },
      "source": [
        "# Define per-fold score containers\r\n",
        "acc_per_fold = []\r\n",
        "loss_per_fold = []\r\n",
        "\r\n",
        "# K-fold Cross Validation model evaluation\r\n",
        "fold_no = 1\r\n",
        "for train, test in kfold.split(X, y_gender):\r\n",
        "    \r\n",
        "  # Set Seed\r\n",
        "  random.seed(11)\r\n",
        "  set_seed(11)\r\n",
        "  np.random.seed(11)\r\n",
        "  \r\n",
        "  # Define the model architecture\r\n",
        "  model = Sequential()\r\n",
        "  \r\n",
        "  model.add(Conv2D(64, kernel_size=(3,3), input_shape=input_shape, activation='relu'))\r\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "\r\n",
        "  model.add(Conv2D(128, kernel_size=(3,3), activation='relu', padding='same'))\r\n",
        "  model.add(Conv2D(128, kernel_size=(3,3), activation='relu'))\r\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "  model.add(Dropout(0.3))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "\r\n",
        "  model.add(Conv2D(256, kernel_size=(3,3), activation='relu', padding='same'))\r\n",
        "  model.add(Conv2D(256, kernel_size=(3,3), activation='relu'))\r\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "  model.add(Dropout(0.3))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "\r\n",
        "  model.add(Conv2D(512, kernel_size=(3,3), activation='relu', padding='same'))\r\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "  model.add(Dropout(0.5))\r\n",
        "  model.add(BatchNormalization())\r\n",
        "\r\n",
        "  model.add(Flatten())\r\n",
        "  model.add(Dense(128, activation='relu'))\r\n",
        "  model.add(Dense(128, activation='softmax'))\r\n",
        "\r\n",
        "  # Compile the model\r\n",
        "  model.compile(loss=loss_function,\r\n",
        "              optimizer=optimizer,\r\n",
        "              metrics=['accuracy'])\r\n",
        "  \r\n",
        "  # Generate a print\r\n",
        "  print('------------------------------------------------------------------------')\r\n",
        "  print(f'Training for fold {fold_no} ...')\r\n",
        "    \r\n",
        "  early_stop = EarlyStopping(monitor=\"val_loss\",patience=5,mode=\"min\") # Ensure the model doesn't overfit\r\n",
        "  \r\n",
        "  # Set Seed\r\n",
        "  random.seed(11)\r\n",
        "  set_seed(11)\r\n",
        "  np.random.seed(11)\r\n",
        "    \r\n",
        "  # Fit data to model\r\n",
        "  history = model.fit(train_data_gen.flow(X[train], y_gender[train], seed=11),\r\n",
        "            callbacks=early_stop,\r\n",
        "            batch_size=batch_size,\r\n",
        "            epochs=no_epochs,\r\n",
        "            verbose=verbosity,\r\n",
        "            validation_data=train_data_gen.flow(X[test], y_gender[test],\r\n",
        "                                   seed=11))\r\n",
        "  \r\n",
        "  # Generate generalization metrics\r\n",
        "  fig = px.line(\r\n",
        "  history.history, y=['loss', 'val_loss'],\r\n",
        "  labels={'index': 'epoch', 'value': 'loss'}, \r\n",
        "  title='Training History')\r\n",
        "  fig.show()\r\n",
        "    \r\n",
        "  scores = model.evaluate(train_data_gen.flow(X[test], y_gender[test],\r\n",
        "                                   seed=11), verbose=0)\r\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\r\n",
        "  acc_per_fold.append(scores[1] * 100)\r\n",
        "  loss_per_fold.append(scores[0])\r\n",
        "  \r\n",
        "  # Increase fold number\r\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}